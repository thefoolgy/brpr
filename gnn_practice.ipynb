{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c3c741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9030d240",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:/brpr/dataset/brenda_rm.csv')\n",
    "\n",
    "# Convert SMILES to RDKit Mol objects\n",
    "df['substrate_mol'] = df['smiles'].apply(Chem.MolFromSmiles)\n",
    "df['product_mol'] = df['product_smile'].apply(Chem.MolFromSmiles)\n",
    "unique_ec_numbers = df['EC Number'].unique()\n",
    "ec_to_index = {ec: idx for idx, ec in enumerate(unique_ec_numbers)}\n",
    "df['EC Index'] = df['EC Number'].map(ec_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d7f5530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atom_feature(atom):\n",
    "    return [\n",
    "        atom.GetAtomicNum(),\n",
    "        atom.GetTotalValence(),\n",
    "        atom.GetDegree(),\n",
    "        atom.IsInRing(),\n",
    "        atom.GetFormalCharge(),\n",
    "        atom.GetNumRadicalElectrons()\n",
    "    ]\n",
    "\n",
    "def bond_feature(bond):\n",
    "    bond_type = bond.GetBondType()\n",
    "    return [\n",
    "        bond_type == Chem.rdchem.BondType.SINGLE,\n",
    "        bond_type == Chem.rdchem.BondType.DOUBLE,\n",
    "        bond_type == Chem.rdchem.BondType.TRIPLE,\n",
    "        bond_type == Chem.rdchem.BondType.AROMATIC,\n",
    "        bond.IsInRing()\n",
    "    ]\n",
    "\n",
    "def molecule_to_graph(mol):\n",
    "    atom_features = [atom_feature(atom) for atom in mol.GetAtoms()]\n",
    "    bond_indices = []\n",
    "    bond_features = []\n",
    "    for bond in mol.GetBonds():\n",
    "        start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "        bond_indices.append((start, end))\n",
    "        bond_indices.append((end, start))\n",
    "        bond_features.extend([bond_feature(bond)] * 2)\n",
    "\n",
    "    x = torch.tensor(atom_features, dtype=torch.float)\n",
    "    edge_index = torch.tensor(bond_indices, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(bond_features, dtype=torch.float)\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "df['substrate_graph'] = df['substrate_mol'].apply(molecule_to_graph)\n",
    "df['product_graph'] = df['product_mol'].apply(molecule_to_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "499ee881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class MolecularDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        substrate_graph = self.data.iloc[idx]['substrate_graph']\n",
    "        enzyme_index = self.data.iloc[idx]['EC Index']\n",
    "        product_graph = self.data.iloc[idx]['product_graph']\n",
    "        \n",
    "        return substrate_graph, enzyme_index, product_graph\n",
    "\n",
    "# Splitting the data into training and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = MolecularDataset(train_df)\n",
    "test_dataset = MolecularDataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "368f42df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Batch\n",
    "\n",
    "def collate_fn(batch):\n",
    "    substrate_data, enzyme_data, true_product_data = zip(*batch)\n",
    "    \n",
    "    # Collate substrate and product data using Batch.from_data_list\n",
    "    substrate_data = Batch.from_data_list(list(substrate_data))\n",
    "    true_product_data = Batch.from_data_list(list(true_product_data))\n",
    "    \n",
    "    # Convert enzyme_data to tensor\n",
    "    enzyme_data = torch.tensor(enzyme_data, dtype=torch.long)\n",
    "    \n",
    "    return substrate_data, enzyme_data, true_product_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "966a26e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56275006",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "00892d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformationEncoderDecoder(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels, transformation_dim, heads, num_enzymes, enzyme_embedding_dim):\n",
    "        super(TransformationEncoderDecoder, self).__init__()\n",
    "\n",
    "        # Enzyme embedding\n",
    "        self.enzyme_embedding = torch.nn.Embedding(num_enzymes, enzyme_embedding_dim)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder_conv1 = GATConv(num_node_features, hidden_channels, heads=heads, dropout=0.6)\n",
    "        self.encoder_conv2 = GATConv(hidden_channels * heads, hidden_channels, heads=heads, dropout=0.6)\n",
    "        self.encoder_fc = torch.nn.Linear(hidden_channels * heads + enzyme_embedding_dim, 256)  # Adjusted for enzyme embedding\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder_fc = torch.nn.Linear(256, 256)\n",
    "        \n",
    "    def encode_molecule(self, molecule_data, enzyme_data):\n",
    "        x, edge_index = molecule_data.x, molecule_data.edge_index\n",
    "        x = F.elu(self.encoder_conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.elu(self.encoder_conv2(x, edge_index))\n",
    "        global_representation = torch.mean(x, dim=0, keepdim=True)\n",
    "        enzyme_embed = self.enzyme_embedding(enzyme_data)\n",
    "\n",
    "        # Repeat the global_representation to match the batch size of enzyme_embed\n",
    "        global_representation = global_representation.repeat(enzyme_embed.size(0), 1)\n",
    "\n",
    "        combined_representation = torch.cat([global_representation, enzyme_embed], dim=1)\n",
    "        transformation_representation = self.encoder_fc(combined_representation)\n",
    "        return transformation_representation\n",
    "\n",
    "\n",
    "    def forward(self, substrate_data, enzyme_data):\n",
    "        # Encoder\n",
    "        x, edge_index = substrate_data.x, substrate_data.edge_index\n",
    "        x = F.elu(self.encoder_conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.elu(self.encoder_conv2(x, edge_index))\n",
    "        global_representation = torch.mean(x, dim=0, keepdim=True)  # Global pooling\n",
    "        #enzyme embed\n",
    "        enzyme_embed = self.enzyme_embedding(enzyme_data)\n",
    "        global_representation = global_representation.repeat(enzyme_embed.size(0), 1)\n",
    "        # Concatenate enzyme embedding with substrate representation\n",
    "        combined_representation = torch.cat([global_representation, enzyme_embed], dim=1)\n",
    "\n",
    "        transformation_representation = self.encoder_fc(combined_representation)\n",
    "\n",
    "        # Decoder\n",
    "        predicted_product = self.decoder_fc(transformation_representation)\n",
    "\n",
    "        return predicted_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ed4c485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_enzymes = len(unique_ec_numbers)\n",
    "enzyme_embedding_dim = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc76425",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a3523acb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.0006558131486973142\n",
      "Epoch 2/100, Loss: 1.829552584037256e-05\n",
      "Epoch 3/100, Loss: 1.4227179618572512e-05\n",
      "Epoch 4/100, Loss: 8.075902338517595e-06\n",
      "Epoch 5/100, Loss: 3.844186295026517e-06\n",
      "Epoch 6/100, Loss: 1.7774302896262657e-06\n",
      "Epoch 7/100, Loss: 6.79058255036624e-07\n",
      "Epoch 8/100, Loss: 2.6039528443067773e-07\n",
      "Epoch 9/100, Loss: 4.9518285040296775e-05\n",
      "Epoch 10/100, Loss: 1.2193840172204423e-06\n",
      "Epoch 11/100, Loss: 4.5149615713912974e-07\n",
      "Epoch 12/100, Loss: 2.965127977951899e-07\n",
      "Epoch 13/100, Loss: 1.5811131291847205e-07\n",
      "Epoch 14/100, Loss: 8.789290360117238e-08\n",
      "Epoch 15/100, Loss: 4.3865475555180425e-08\n",
      "Epoch 16/100, Loss: 1.5095450043501728e-05\n",
      "Epoch 17/100, Loss: 1.6041215626228587e-07\n",
      "Epoch 18/100, Loss: 1.1528275722328844e-07\n",
      "Epoch 19/100, Loss: 1.0832541134067416e-07\n",
      "Epoch 20/100, Loss: 2.4614259034426577e-08\n",
      "Epoch 21/100, Loss: 4.177422168117011e-05\n",
      "Epoch 22/100, Loss: 3.7546256061768175e-07\n",
      "Epoch 23/100, Loss: 2.61807917587423e-07\n",
      "Epoch 24/100, Loss: 6.330181521412273e-07\n",
      "Epoch 25/100, Loss: 3.1653694874990105e-08\n",
      "Epoch 26/100, Loss: 5.0571271563884524e-08\n",
      "Epoch 27/100, Loss: 2.1885308884765826e-08\n",
      "Epoch 28/100, Loss: 2.617306435250704e-05\n",
      "Epoch 29/100, Loss: 4.0326826954056203e-07\n",
      "Epoch 30/100, Loss: 1.4980819195784258e-07\n",
      "Epoch 31/100, Loss: 8.316786660963809e-07\n",
      "Epoch 32/100, Loss: 4.569573265070244e-08\n",
      "Epoch 33/100, Loss: 1.3882625740901356e-08\n",
      "Epoch 34/100, Loss: 2.0016065103035894e-05\n",
      "Epoch 35/100, Loss: 3.7046633249054806e-07\n",
      "Epoch 36/100, Loss: 1.3217952085969926e-07\n",
      "Epoch 37/100, Loss: 1.1641190311992503e-07\n",
      "Epoch 38/100, Loss: 5.549099781327422e-05\n",
      "Epoch 39/100, Loss: 3.41670787407429e-06\n",
      "Epoch 40/100, Loss: 4.490123782562768e-07\n",
      "Epoch 41/100, Loss: 2.576562516368915e-07\n",
      "Epoch 42/100, Loss: 1.43920447108518e-07\n",
      "Epoch 43/100, Loss: 4.0770164882396e-05\n",
      "Epoch 44/100, Loss: 3.4511229214603457e-07\n",
      "Epoch 45/100, Loss: 1.4767123838632333e-07\n",
      "Epoch 46/100, Loss: 9.824386003786974e-08\n",
      "Epoch 47/100, Loss: 5.6653748508964355e-08\n",
      "Epoch 48/100, Loss: 3.4730097159816133e-08\n",
      "Epoch 49/100, Loss: 1.8329663914578486e-08\n",
      "Epoch 50/100, Loss: 1.1190198330642075e-05\n",
      "Epoch 51/100, Loss: 6.21966947696012e-08\n",
      "Epoch 52/100, Loss: 4.487297710442397e-08\n",
      "Epoch 53/100, Loss: 1.5914469331375057e-05\n",
      "Epoch 54/100, Loss: 3.5921273857260547e-07\n",
      "Epoch 55/100, Loss: 1.0618550681166888e-07\n",
      "Epoch 56/100, Loss: 8.450500589091851e-08\n",
      "Epoch 57/100, Loss: 5.5777411289994765e-08\n",
      "Epoch 58/100, Loss: 3.164481077471452e-05\n",
      "Epoch 59/100, Loss: 6.131239311351359e-07\n",
      "Epoch 60/100, Loss: 2.859793903136639e-07\n",
      "Epoch 61/100, Loss: 2.2437713260831e-07\n",
      "Epoch 62/100, Loss: 1.6056997644071079e-06\n",
      "Epoch 63/100, Loss: 2.110351922547566e-08\n",
      "Epoch 64/100, Loss: 0.00014592094884591556\n",
      "Epoch 65/100, Loss: 4.2360230488673545e-06\n",
      "Epoch 66/100, Loss: 1.0979958530291835e-06\n",
      "Epoch 67/100, Loss: 5.150685680066755e-07\n",
      "Epoch 68/100, Loss: 2.5002351284123823e-07\n",
      "Epoch 69/100, Loss: 1.4523749280329842e-07\n",
      "Epoch 70/100, Loss: 6.999691870708563e-08\n",
      "Epoch 71/100, Loss: 1.373525241920457e-05\n",
      "Epoch 72/100, Loss: 1.1001338780501454e-07\n",
      "Epoch 73/100, Loss: 6.901350680010837e-08\n",
      "Epoch 74/100, Loss: 6.574375737761883e-08\n",
      "Epoch 75/100, Loss: 5.116620120955402e-08\n",
      "Epoch 76/100, Loss: 1.8290433351324872e-05\n",
      "Epoch 77/100, Loss: 2.248325850463858e-06\n",
      "Epoch 78/100, Loss: 1.2459136136689838e-07\n",
      "Epoch 79/100, Loss: 1.1821533726081849e-07\n",
      "Epoch 80/100, Loss: 8.351122334440444e-08\n",
      "Epoch 81/100, Loss: 0.00014179839156070042\n",
      "Epoch 82/100, Loss: 1.9942015494876745e-06\n",
      "Epoch 83/100, Loss: 6.413915550389452e-07\n",
      "Epoch 84/100, Loss: 3.7686720009100423e-07\n",
      "Epoch 85/100, Loss: 3.759677201621179e-07\n",
      "Epoch 86/100, Loss: 7.353894110315571e-08\n",
      "Epoch 87/100, Loss: 5.8385623958454556e-05\n",
      "Epoch 88/100, Loss: 1.6794571140788135e-06\n",
      "Epoch 89/100, Loss: 4.0256866075306067e-07\n",
      "Epoch 90/100, Loss: 2.578919924379014e-07\n",
      "Epoch 91/100, Loss: 1.7460208555517343e-07\n",
      "Epoch 92/100, Loss: 1.1915156919917676e-05\n",
      "Epoch 93/100, Loss: 2.964374042605928e-07\n",
      "Epoch 94/100, Loss: 9.033039555614344e-08\n",
      "Epoch 95/100, Loss: 6.193781770584053e-08\n",
      "Epoch 96/100, Loss: 4.52703503504909e-08\n",
      "Epoch 97/100, Loss: 2.004791565504339e-05\n",
      "Epoch 98/100, Loss: 1.735033622532053e-07\n",
      "Epoch 99/100, Loss: 1.1356938097414175e-07\n",
      "Epoch 100/100, Loss: 7.07492869991931e-08\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Initialize the model, criterion, and optimizer\n",
    "model = TransformationEncoderDecoder(num_node_features=6,  # Assuming 6 features per node\n",
    "                                    hidden_channels=64,\n",
    "                                    transformation_dim=128,\n",
    "                                    heads=4,\n",
    "                                    num_enzymes=num_enzymes,\n",
    "                                    enzyme_embedding_dim=32).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for substrate_data, enzyme_data, true_product_data in train_loader:\n",
    "        substrate_data, enzyme_data, true_product_data = substrate_data.to(device), enzyme_data.to(device), true_product_data.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predicted_product = model(substrate_data, enzyme_data)\n",
    "        true_product_representation = model.encode_molecule(true_product_data, enzyme_data)\n",
    "        loss = criterion(predicted_product, true_product_representation)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4a7cbb",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "95196df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.5817973505802655e-08\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total_loss = 0\n",
    "with torch.no_grad():\n",
    "    for substrate_data, enzyme_data, true_product_data in test_loader:\n",
    "        substrate_data, enzyme_data, true_product_data = substrate_data.to(device), enzyme_data.to(device), true_product_data.to(device)\n",
    "        \n",
    "        predicted_product = model(substrate_data, enzyme_data)\n",
    "        true_product_representation = model.encode_molecule(true_product_data, enzyme_data)\n",
    "        loss = criterion(predicted_product, true_product_representation)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "print(f\"Test Loss: {total_loss/len(test_loader)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
